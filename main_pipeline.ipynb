{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lolapi import RiotUnofficialApi\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "DATA_LOCATION = \"./data/riot/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = RiotUnofficialApi(\n",
    "        api_key=\"0TvQnueqKa5mxJntVWt0w4LpLfEkrV1Ta8rQBb9Z\",\n",
    "        lang=\"en-US\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/05 10:20:49 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/08/05 10:20:49 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/08/05 10:20:49 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 75.08% for 9 writers\n",
      "23/08/05 10:20:49 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 67.58% for 10 writers\n",
      "23/08/05 10:20:49 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 61.43% for 11 writers\n",
      "23/08/05 10:20:49 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 56.31% for 12 writers\n",
      "23/08/05 10:20:49 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 61.43% for 11 writers\n",
      "23/08/05 10:20:49 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 67.58% for 10 writers\n",
      "23/08/05 10:20:49 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 75.08% for 9 writers\n",
      "23/08/05 10:20:49 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/08/05 10:20:49 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "leagues = api.get_leagues()\n",
    "leagues_df = spark.createDataFrame(leagues)\n",
    "(\n",
    "    leagues_df\n",
    "    .write\n",
    "    .parquet(DATA_LOCATION + 'leagues/', mode='overwrite')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/05 10:21:22 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n"
     ]
    }
   ],
   "source": [
    "tournament_list = []\n",
    "for league in leagues:\n",
    "    tournament_list.extend(api.get_tournaments(league_id=league['id']))\n",
    "\n",
    "tournament_df = spark.createDataFrame(tournament_list)\n",
    "\n",
    "(\n",
    "    tournament_df\n",
    "    .write\n",
    "    .mode('overwrite')\n",
    "    .parquet(DATA_LOCATION + 'tournaments')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType\n",
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "\n",
    "result_schema = StructType([\n",
    "    StructField(\"outcome\", StringType(), nullable=True),\n",
    "    StructField(\"gameWins\", IntegerType(), nullable=True)\n",
    "])\n",
    "\n",
    "team_schema = StructType([\n",
    "    StructField(\"id\", StringType(), nullable=True),\n",
    "    StructField(\"slug\", StringType(), nullable=True),\n",
    "    StructField(\"name\", StringType(), nullable=True),\n",
    "    StructField(\"code\", StringType(), nullable=True),\n",
    "    StructField(\"image\", StringType(), nullable=True),\n",
    "    StructField(\"result\", result_schema, nullable=True)\n",
    "])\n",
    "\n",
    "match_schema = StructType([\n",
    "    StructField(\"id\", StringType(), nullable=True),\n",
    "    StructField(\"state\", StringType(), nullable=True),\n",
    "    StructField(\"previousMatchIds\", StringType(), nullable=True),\n",
    "    StructField(\"flags\", ArrayType(StringType()), nullable=True),\n",
    "    StructField(\"teams\", ArrayType(team_schema), nullable=True)\n",
    "])\n",
    "\n",
    "rankings_schema = StructType([\n",
    "    StructField(\"ordinal\", IntegerType(), nullable=True),\n",
    "    StructField(\"teams\", ArrayType(team_schema), nullable=True)\n",
    "])\n",
    "\n",
    "sections_schema = StructType([\n",
    "    StructField(\"name\", StringType(), nullable=True),\n",
    "    StructField(\"matches\", ArrayType(match_schema), nullable=True),\n",
    "    StructField(\"rankings\", ArrayType(rankings_schema), nullable=True)\n",
    "])\n",
    "\n",
    "stages_schema = StructType([\n",
    "    StructField(\"name\", StringType(), nullable=True),\n",
    "    StructField(\"type\", StringType(), nullable=True),\n",
    "    StructField(\"slug\", StringType(), nullable=True),\n",
    "    StructField(\"sections\", ArrayType(sections_schema), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def explode_column(df: DataFrame, column_name: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Explode a specified column in a DataFrame and transform each record from the array into a new line.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame.\n",
    "        column_name (str): The name of the column to explode.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: The DataFrame with the specified column exploded.\n",
    "    \"\"\"\n",
    "    # Explode the specified column\n",
    "    \n",
    "    exploded_df = df.selectExpr(\"*\", f\"explode({column_name}) as {column_name}_exploded\")\n",
    "    \n",
    "    # Explode the exploded struct column into individual columns with the parent column name as prefix\n",
    "    # final_df = exploded_df.selectExpr(\"*\", f\"{column_name}_exploded.*\").drop(f\"{column_name}_exploded\")\n",
    "    for col_name in exploded_df.schema[column_name + \"_exploded\"].dataType.names:\n",
    "        exploded_df = exploded_df.withColumn(f\"{column_name}_{col_name}\", col(f\"{column_name}_exploded.{col_name}\"))\n",
    "    \n",
    "    exploded_df = exploded_df.drop(f\"{column_name}_exploded\")\n",
    "    exploded_df = exploded_df.drop(f\"{column_name}\")\n",
    "    \n",
    "    return exploded_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages_list = []\n",
    "for tournament in tournament_list:\n",
    "    standings = api.get_standings(tournament_list[0]['id'])\n",
    "    stages_list.extend(standings[0]['stages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "standings_df = spark.createDataFrame(stages_list, schema=stages_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "standings_df_final = (\n",
    "    standings_df\n",
    "    .transform(explode_column, \"sections\")\n",
    "    .transform(explode_column, \"sections_matches\")\n",
    "    .transform(explode_column, \"sections_rankings\")\n",
    "    .transform(explode_column, \"sections_matches_teams\")\n",
    "    .transform(explode_column, \"sections_rankings_teams\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+--------------+--------------+-------------------+----------------------+---------------------------------+----------------------+-------------------------+-------------------------+---------------------------+---------------------------+---------------------------+----------------------------+-----------------------------+--------------------------+----------------------------+----------------------------+----------------------------+-----------------------------+------------------------------+\n",
      "|          name|type|          slug| sections_name|sections_matches_id|sections_matches_state|sections_matches_previousMatchIds|sections_matches_flags|sections_rankings_ordinal|sections_matches_teams_id|sections_matches_teams_slug|sections_matches_teams_name|sections_matches_teams_code|sections_matches_teams_image|sections_matches_teams_result|sections_rankings_teams_id|sections_rankings_teams_slug|sections_rankings_teams_name|sections_rankings_teams_code|sections_rankings_teams_image|sections_rankings_teams_result|\n",
      "+--------------+----+--------------+--------------+-------------------+----------------------+---------------------------------+----------------------+-------------------------+-------------------------+---------------------------+---------------------------+---------------------------+----------------------------+-----------------------------+--------------------------+----------------------------+----------------------------+----------------------------+-----------------------------+------------------------------+\n",
      "|Regular Season|null|regular_season|Regular Season| 110303581088069312|             completed|                             null|              [hasVod]|                        1|        99294153828264740|                100-thieves|                100 Thieves|                        100|        http://static.lol...|                    {loss, 0}|         98767991877340524|                      cloud9|                      Cloud9|                          C9|         http://static.lol...|                          null|\n",
      "|Regular Season|null|regular_season|Regular Season| 110303581088069312|             completed|                             null|              [hasVod]|                        1|        98767991877340524|                     cloud9|                     Cloud9|                         C9|        http://static.lol...|                     {win, 1}|         98767991877340524|                      cloud9|                      Cloud9|                          C9|         http://static.lol...|                          null|\n",
      "|Regular Season|null|regular_season|Regular Season| 110303581088069312|             completed|                             null|              [hasVod]|                        2|        99294153828264740|                100-thieves|                100 Thieves|                        100|        http://static.lol...|                    {loss, 0}|         99294153824386385|            golden-guardians|            Golden Guardians|                          GG|         http://static.lol...|                          null|\n",
      "+--------------+----+--------------+--------------+-------------------+----------------------+---------------------------------+----------------------+-------------------------+-------------------------+---------------------------+---------------------------+---------------------------+----------------------------+-----------------------------+--------------------------+----------------------------+----------------------------+----------------------------+-----------------------------+------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standings_df_final.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/05 10:23:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/08/05 10:23:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/08/05 10:23:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 75.08% for 9 writers\n",
      "23/08/05 10:23:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 67.58% for 10 writers\n",
      "23/08/05 10:23:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 61.43% for 11 writers\n",
      "23/08/05 10:23:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 56.31% for 12 writers\n",
      "23/08/05 10:23:06 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 61.43% for 11 writers\n",
      "23/08/05 10:23:06 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 67.58% for 10 writers\n",
      "23/08/05 10:23:06 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 75.08% for 9 writers\n",
      "23/08/05 10:23:06 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/08/05 10:23:06 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    standings_df_final\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(DATA_LOCATION + \"standings/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_list = api.get_teams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/05 10:23:08 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/08/05 10:23:08 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/08/05 10:23:08 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/08/05 10:23:08 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/08/05 10:23:08 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+----+--------------------+------------------+--------------------+----+-------+----+--------+\n",
      "|    alternativeImage|backgroundImage|code|          homeLeague|                id|               image|name|players|slug|  status|\n",
      "+--------------------+---------------+----+--------------------+------------------+--------------------+----+-------+----+--------+\n",
      "|https://lolstatic...|           null|TBDD|{name -> MSI, reg...|100205572995797818|https://lolstatic...| TBD|     []| tbd|archived|\n",
      "|https://lolstatic...|           null|TBDA|{name -> MSI, reg...|100205572997632804|https://lolstatic...| TBD|     []| tbd|archived|\n",
      "|https://lolstatic...|           null|TBDC|{name -> MSI, reg...|100205572999591608|https://lolstatic...| TBD|     []| tbd|archived|\n",
      "+--------------------+---------------+----+--------------------+------------------+--------------------+----+-------+----+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teams_df = spark.createDataFrame(teams_list)\n",
    "\n",
    "(\n",
    "    teams_df\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(DATA_LOCATION + \"teams/\")\n",
    ")\n",
    "teams_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_details_list = []\n",
    "for match_reg in standings_df_final.groupBy('sections_matches_id').count().collect():\n",
    "    match_details = api.get_match_details(match_id=match_reg['sections_matches_id'])\n",
    "    if match_details:\n",
    "        match_details_list.append(match_details)\n",
    "\n",
    "# match_details = api.get_match_details(match_id=standings_df_final.collect()[-1]['sections_matches_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_details_df = spark.createDataFrame(match_details_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blue_team.players',\n",
       " 'blue_team.esportsTeamId',\n",
       " 'blue_team.totalGold',\n",
       " 'blue_team.inhibitors',\n",
       " 'blue_team.towers',\n",
       " 'blue_team.barons',\n",
       " 'blue_team.totalKills',\n",
       " 'blue_team.dragons']"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"blue_team.{k}\" for k  in match_details_list[0]['blue_team'].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- blue_team: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: array (valueContainsNull = true)\n",
      " |    |    |-- element: map (containsNull = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: long (valueContainsNull = true)\n",
      " |-- red_team: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: array (valueContainsNull = true)\n",
      " |    |    |-- element: map (containsNull = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: long (valueContainsNull = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match_details_df.printSchema()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
